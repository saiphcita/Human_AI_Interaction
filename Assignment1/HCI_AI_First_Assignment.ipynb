{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HCI-AI: First Assignment",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H6I07NcZEDM"
      },
      "source": [
        "\n",
        "\n",
        "# 1st Homework Assignment in Human A.I. \n",
        "\n",
        "This assignment will ramp you up on being able to process large scale data sets and use them for Human A.I. interaction. We will work in particular with the dataset of full_home_loans.csv which is about home loan applications in Washington state, USA, where each row of the dataset is an individual loan application. \n",
        "\n",
        "**Goal.** Your goal in this assignment is to build a machine learning model that can accurately predict whether a given loan application was accepted or rejected. In order to accomplish this you will learn skills to: (1)  process large scale data; (2) preparing the data for the machine learning models; (3) developing machine learning models.(4) creating your own machine learning datasets. \n",
        "\n",
        "\n",
        "**Part 1: Data Exploration**\n",
        "The first few exercises will get you used to looking at the data using pandas. Pandas is a widely used library in python for manipulating data. Why? Datasets can consume a lot of space in your computer's memory and traditional python data structures like lists or dictionaries will become painfully slow as we add thousands of rows of data. We use a specialized dataset library pandas which has a specialized data structure called a dataframe designed to be ultra fast & efficient. Documentation is here: https://pandas.pydata.org/pandas-docs/stable/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "GHyotj7rG1oX",
        "outputId": "6f13eeae-7bae-4e81-cd8a-bcc9e851a38a"
      },
      "source": [
        "\n",
        "from google.colab import files \n",
        "from __future__ import print_function\n",
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "  \n",
        "#Code to upload the dataset from your computer as a dataframe\n",
        "uploaded = files.upload()\n",
        "nameFile=\"home_loans.csv\"\n",
        "bytesFile=io.BytesIO(uploaded[nameFile])\n",
        "df=pd.read_csv(bytesFile, sep=\",\")\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4f8228d0-1487-41d2-95a2-5d8695f87742\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4f8228d0-1487-41d2-95a2-5d8695f87742\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving home_loans.csv to home_loans (1).csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (10,11,12,14,15,16,21,22,23) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnkuWN8YZA7Z"
      },
      "source": [
        "# `Processing Data Using Pandas`\n",
        "\n",
        "To understand what kind of data was collected, pandas has some handy commands:\n",
        "\n",
        "* **df.head()** will show us the first 5 rows of our dataset. You can \n",
        "also specify the first N rows, like df.head(18) will show us the first 18 rows.\n",
        "* **df.sample(10)** will show us 10 randomly sampled rows of our dataset\n",
        "* **df.shape** will tell us how many rows and how many columns are in the dataset\n",
        "* **df.columns** will list the names of all columns in the dataset\n",
        "* **df.describe()** will give you summary statistics about all numerical columns in the dataset\n",
        "\n",
        "\n",
        "## Question 1.A: How many rows are in this dataset? How many columns?\n",
        "\n",
        " Show your work in code below if applicable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCpRDoPmKGnX"
      },
      "source": [
        "\n",
        "#Add your response and code here:"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTUr4YzMVSBy"
      },
      "source": [
        "## Question 1.B: One of the columns in the dataset is the outcome value for each application, the value we will try to predict. Which column is that?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce_uEQBCTY36"
      },
      "source": [
        "#Add your response and code here:\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyvfYYK1s_ez"
      },
      "source": [
        "## Question 1.C: What reasons were given in this dataset for denying a loan application?\n",
        "\n",
        "Hint: There are 3 columns in the dataset that list why a loan was denied. Try looking up the pandas command to list the unique values in a column.\n",
        "\n",
        "Show your work in code below if applicable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SUMRVl1SN1K"
      },
      "source": [
        "#Add your response and code here:"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzExp_1tuUqc"
      },
      "source": [
        "## Question 1.D: Given the denial reasons and the columns in this dataset, think about what information you don't have about each application. Rank your top 3 missing pieces of information about each application that could help you better predict the application's loan outcome.\n",
        "\n",
        "Show your work in code below if applicable.\n",
        "\n",
        "\n",
        "\n",
        "1.   \n",
        "2.   \n",
        "3. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UEG-Ws5uqBt"
      },
      "source": [
        "#Add your response here. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiVhPf74vQ-N"
      },
      "source": [
        "# **Part 2: Preparing Data to Input to a Model**\n",
        "\n",
        "Here we'll start using scikit-learn which provides simple library calls for most things we'd like to do in a simple machine learning pipeline. If you haven't used scikit-learn before this tutorial may be useful to give you a sense of what the library can do: https://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
        "\n",
        "Machine learning models can only understand data that is represented numerically, but lots of the columns in our dataset like \"town_name\" are text categorical data. Meanwhile, many models do better when continous numerical data is within small, consistent ranges, such as all data being between -1, 0 and 1, which is definitely not the case with our thousands of dollars loan units.\n",
        "\n",
        "So first, we will seperate out our samples (called X) into features we'd like to include in our model that are categorical or continous so that we can preprocess each appropriately seperately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aMAtGe1hm_n",
        "outputId": "44cf702e-eb9f-4245-b64c-c61c8fd0f6b2"
      },
      "source": [
        "import sklearn # import scikit-learn\n",
        "from sklearn import preprocessing # import preprocessing utilites\n",
        "\n",
        "features_cat = ['loan_purpose_name', 'applicant_sex_name']\n",
        "features_num = ['loan_amount_000s', 'applicant_income_000s']\n",
        "\n",
        "X_cat = df[features_cat]\n",
        "print (X_cat)\n",
        "X_num = df[features_num]\n",
        "print (X_num)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       loan_purpose_name applicant_sex_name\n",
            "0            Refinancing             Female\n",
            "1          Home purchase               Male\n",
            "2            Refinancing               Male\n",
            "3            Refinancing               Male\n",
            "4       Home improvement             Female\n",
            "...                  ...                ...\n",
            "369276     Home purchase             Female\n",
            "369277     Home purchase               Male\n",
            "369278     Home purchase             Female\n",
            "369279     Home purchase               Male\n",
            "369280     Home purchase               Male\n",
            "\n",
            "[369281 rows x 2 columns]\n",
            "        loan_amount_000s  applicant_income_000s\n",
            "0                    227                  116.0\n",
            "1                    240                   42.0\n",
            "2                    241                  117.0\n",
            "3                    351                  315.0\n",
            "4                    417                  114.0\n",
            "...                  ...                    ...\n",
            "369276               178                   97.0\n",
            "369277               110                   30.0\n",
            "369278               420                   71.0\n",
            "369279               255                   77.0\n",
            "369280               319                   78.0\n",
            "\n",
            "[369281 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpGc1XOcxKxW"
      },
      "source": [
        "**Part 2.A One Hot Encode Categorical Variables**\n",
        "\n",
        "Run the following code to one hot encode the categorical features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A8S4HM3iXA7"
      },
      "source": [
        "enc = preprocessing.OneHotEncoder()\n",
        "enc.fit(X_cat) # fit the encoder to categories in our data \n",
        "one_hot = enc.transform(X_cat) # transform data into one hot encoded sparse array format\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "oDzyLuQ4igJz",
        "outputId": "6c54a139-0124-47b2-8691-6d6008bd0bf1"
      },
      "source": [
        "# Finally, put the newly encoded sparse array back into a pandas dataframe so that we can use it\n",
        "X_cat_proc = pd.DataFrame(one_hot.toarray(), columns=enc.get_feature_names())\n",
        "X_cat_proc.head()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x0_Home improvement</th>\n",
              "      <th>x0_Home purchase</th>\n",
              "      <th>x0_Refinancing</th>\n",
              "      <th>x1_Female</th>\n",
              "      <th>x1_Information not provided by applicant in mail, Internet, or telephone application</th>\n",
              "      <th>x1_Male</th>\n",
              "      <th>x1_Not applicable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x0_Home improvement  x0_Home purchase  ...  x1_Male  x1_Not applicable\n",
              "0                  0.0               0.0  ...      0.0                0.0\n",
              "1                  0.0               1.0  ...      1.0                0.0\n",
              "2                  0.0               0.0  ...      1.0                0.0\n",
              "3                  0.0               0.0  ...      1.0                0.0\n",
              "4                  1.0               0.0  ...      0.0                0.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoP73Jdr1aAZ"
      },
      "source": [
        "##Question 2.A: In your own words, how is one hot coding tranforming the categorical data? What does the term \"one-hot\" refer to?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fac7Bbp71i0e"
      },
      "source": [
        "#Add your response here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "je0Fwp2F2uVF"
      },
      "source": [
        "## Part 2.B Scaling down continuous numerical data\n",
        "Run the following code to normalize any continous numberical features, such as loan dollar amount, between -1 and 0. This process will ensure that the average of that feature, such as the average amount that a person asks for in loan amount, is scaled to 0. Values less than the average will be negative numbers, and values larger than the average will be positive numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9fYIhmSIigLK",
        "outputId": "e7127b0b-cc28-4751-f29e-f1fd601a38d6"
      },
      "source": [
        "scaled = preprocessing.scale(X_num)\n",
        "X_num_proc = pd.DataFrame(scaled, columns=features_num)\n",
        "X_num_proc.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loan_amount_000s</th>\n",
              "      <th>applicant_income_000s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.130864</td>\n",
              "      <td>0.016448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.103680</td>\n",
              "      <td>-0.596232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.101589</td>\n",
              "      <td>0.024727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.128424</td>\n",
              "      <td>1.664059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.266432</td>\n",
              "      <td>-0.000111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   loan_amount_000s  applicant_income_000s\n",
              "0         -0.130864               0.016448\n",
              "1         -0.103680              -0.596232\n",
              "2         -0.101589               0.024727\n",
              "3          0.128424               1.664059\n",
              "4          0.266432              -0.000111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5d3FHA0259Z"
      },
      "source": [
        "## Part 2.C Merge our feature sets into one sample dataset X and fix NaN values\n",
        "Run the code below to combine the numerical and categorical feature sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "APPrp9QtjFxH",
        "outputId": "e4eb716b-c3f8-408a-dd24-43073c7dd74c"
      },
      "source": [
        "X = pd.concat([X_num_proc, X_cat_proc], axis=1, sort=False)\n",
        "X.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loan_amount_000s</th>\n",
              "      <th>applicant_income_000s</th>\n",
              "      <th>x0_Home improvement</th>\n",
              "      <th>x0_Home purchase</th>\n",
              "      <th>x0_Refinancing</th>\n",
              "      <th>x1_Female</th>\n",
              "      <th>x1_Information not provided by applicant in mail, Internet, or telephone application</th>\n",
              "      <th>x1_Male</th>\n",
              "      <th>x1_Not applicable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.130864</td>\n",
              "      <td>0.016448</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.103680</td>\n",
              "      <td>-0.596232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.101589</td>\n",
              "      <td>0.024727</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.128424</td>\n",
              "      <td>1.664059</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.266432</td>\n",
              "      <td>-0.000111</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   loan_amount_000s  applicant_income_000s  ...  x1_Male  x1_Not applicable\n",
              "0         -0.130864               0.016448  ...      0.0                0.0\n",
              "1         -0.103680              -0.596232  ...      1.0                0.0\n",
              "2         -0.101589               0.024727  ...      1.0                0.0\n",
              "3          0.128424               1.664059  ...      1.0                0.0\n",
              "4          0.266432              -0.000111  ...      0.0                0.0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V27BU98X3E6U"
      },
      "source": [
        "## Question 2.C The code line below removes any NaN values in our sample with 0. NaNs are missing values that a model won't be able to understand. What is the semantic meaning of replaceing a NaN with 0 for the categorical variables? And for the continous numerical variables?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfo_pnQ23LyU"
      },
      "source": [
        "# Add your response here. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE3C92fwjNFA"
      },
      "source": [
        "X = X.fillna(0) # remove NaN values"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D95mk5Z63zZk"
      },
      "source": [
        "## Part 2.D Create our target array y that our model will try to predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNzjnSDSjXa-"
      },
      "source": [
        "y = df['loan_approved'] # target"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCYmmv8m4EEe"
      },
      "source": [
        "## Part 2.E Split our data into training, test, and validation sets\n",
        "Run the code below to split the data. Both validation and test sets will be used for testing our model, but use the validation set while you are developing and improving your model, and leave the test for late stage evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFiOuw5vkCZq",
        "outputId": "1533c014-c378-4342-b155-d8d9d9695424"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_TEMP, y_train, y_TEMP = train_test_split(X, y, test_size=0.30) # split out into training 70% of our data\n",
        "X_validation, X_test, y_validation, y_test = train_test_split(X_TEMP, y_TEMP, test_size=0.50) # split out into validation 15% of our data and test 15% of our data\n",
        "print(X_train.shape, X_validation.shape, X_test.shape) # print data shape to check the sizing is correct"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(258496, 9) (55392, 9) (55393, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W99UMiOJ4NqU"
      },
      "source": [
        "## Question 2.E: In a single sentence, what is the difference between train, test, and validation sets?\n",
        "Post your response below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLoa64r14Rd4"
      },
      "source": [
        "#Write your response here. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsoSi3784XJw"
      },
      "source": [
        "# Part 3. Developing Models\n",
        "Scikit-learn has a substantial library of different models we can use for classification. Below are implemented two of the most simple classification models, Logistic Regression and Dummy Classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uDNQuG3kb-1"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# helper method to print basic model metrics\n",
        "def metrics(y_true, y_pred):\n",
        "    print('Confusion matrix:\\n', confusion_matrix(y_true, y_pred))\n",
        "    print('\\nReport:\\n', classification_report(y_true, y_pred))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOeUMVLKkzTR",
        "outputId": "9c2f979c-f750-40fc-e5b3-919af73e5175"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(solver='lbfgs').fit(X_train, y_train) # first fit (train) the model\n",
        "y_pred = model.predict(X_validation) # next get the model's predictions for a sample in the validation set\n",
        "metrics(y_validation, y_pred) # finally evaluate performance"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            " [[    0  9075]\n",
            " [    0 46317]]\n",
            "\n",
            "Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      9075\n",
            "           1       0.84      1.00      0.91     46317\n",
            "\n",
            "    accuracy                           0.84     55392\n",
            "   macro avg       0.42      0.50      0.46     55392\n",
            "weighted avg       0.70      0.84      0.76     55392\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz3EPQyq4zEs"
      },
      "source": [
        "The Dummy Classifier is a 'dummy' because it is going to use zero machine learning, and simply predict \"approve this loan\" (value 1) for every loan it sees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bjl6KLhlAbx",
        "outputId": "9a96bd9b-c0de-4e34-94cf-bc9339094cbd"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "approve_everyone = DummyClassifier(strategy='constant', constant = 1).fit(X_train, y_train) # first fit (train) the model\n",
        "y_pred_dummy = approve_everyone.predict(X_validation) # next get the model's predictions for a sample in the validation set\n",
        "metrics(y_validation, y_pred_dummy) # finally evaluate performance"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix:\n",
            " [[    0  9075]\n",
            " [    0 46317]]\n",
            "\n",
            "Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      9075\n",
            "           1       0.84      1.00      0.91     46317\n",
            "\n",
            "    accuracy                           0.84     55392\n",
            "   macro avg       0.42      0.50      0.46     55392\n",
            "weighted avg       0.70      0.84      0.76     55392\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWDQb9RD47WM"
      },
      "source": [
        "## Question 3.A: Considering only the data itself, why do Logistic Regression and the Dummy Classifier perform the same? What is the semantic meaning for why Dummy Classifier has such high accuracy?\n",
        "Show your work below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6zyTaQ14-cF"
      },
      "source": [
        "#Add your response here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AlokmX26Ngc"
      },
      "source": [
        "# **Part 4: Your turn!**\n",
        "\n",
        "## Task 4.A: Create a new balanced dataset where exactly half of the samples are rejected loan applications and half are accepted loan application.\n",
        "\n",
        "show your work below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_4RUW6D6ULI"
      },
      "source": [
        "#Add your response here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCXzv9K16WIl"
      },
      "source": [
        "\n",
        "## Task 4.B: Below, retry training and evaluating a Logistic regression model on the updated data.\n",
        "show your work below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDqtyUWB7Aa5"
      },
      "source": [
        "#Add your response here. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYH0dMV47GbM"
      },
      "source": [
        "## Task 4.C: Use your own imagination and experimentation to improve predictive performance for this task, modifying the model choices, feature choices, and data processing however you wish.\n",
        "\n",
        "Important! Your ability to improve the model above the baseline after Task 4.B will count for 10% of this assignment grade, with 5% of that given for modest improvements to performance. Thus while we encourage you to experiment, do not sink excessive time into this task. We will test the performance on our own holdout dataset.\n",
        "\n",
        "show your work below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUAS6haa7KZR"
      },
      "source": [
        "#Add your response here. "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}